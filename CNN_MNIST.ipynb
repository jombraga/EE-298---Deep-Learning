{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jombraga/EE-298---Deep-Learning/blob/master/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSMGtM9Tfv7X",
        "colab_type": "code",
        "outputId": "4b1769c7-8483-4ffa-8661-b099e0ae90b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# load cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# compute the number of labels\n",
        "num_labels = len(np.unique(y_train))\n",
        "\n",
        "# convert to one-hot vector\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# input image dimensions\n",
        "image_size = x_train.shape[1]\n",
        "# resize and normalize\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 3])\n",
        "x_test = np.reshape(x_test,[-1, image_size, image_size, 3])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# network parameters\n",
        "# image is processed as is \n",
        "input_shape = (image_size, image_size, 3)\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "pool_size = 2\n",
        "filters = 64\n",
        "dropout = 0.2\n",
        "\n",
        "# model is a stack of CNN-ReLU-MaxPooling\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())\n",
        "# dropout added as regularizer\n",
        "model.add(Dropout(dropout))\n",
        "# output layer is 10-dim one-hot vector\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "plot_model(model, to_file='cnn-mnist.png', show_shapes=True)\n",
        "\n",
        "# loss function for one-hot vector\n",
        "# use of adam optimizer\n",
        "# accuracy is good metric for classification tasks\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# train the network\n",
        "model.fit(x_train, y_train, epochs=40, batch_size=batch_size)\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 85,898\n",
            "Trainable params: 85,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 1.6488 - acc: 0.3966\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 1.2997 - acc: 0.5368\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 1.1494 - acc: 0.5941\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 1.0560 - acc: 0.6285\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.9863 - acc: 0.6571\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.9309 - acc: 0.6760\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.8883 - acc: 0.6920\n",
            "Epoch 8/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.8542 - acc: 0.7014\n",
            "Epoch 9/40\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 0.8252 - acc: 0.7104\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7964 - acc: 0.7216\n",
            "Epoch 11/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7687 - acc: 0.7340\n",
            "Epoch 12/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7433 - acc: 0.7419\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7253 - acc: 0.7476\n",
            "Epoch 14/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7073 - acc: 0.7524\n",
            "Epoch 15/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6906 - acc: 0.7602\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6709 - acc: 0.7672\n",
            "Epoch 17/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6539 - acc: 0.7709\n",
            "Epoch 18/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6434 - acc: 0.7762\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6222 - acc: 0.7814\n",
            "Epoch 20/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6138 - acc: 0.7862\n",
            "Epoch 21/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5998 - acc: 0.7911\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5892 - acc: 0.7926\n",
            "Epoch 23/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5772 - acc: 0.7978\n",
            "Epoch 24/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5657 - acc: 0.8012\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5580 - acc: 0.8021\n",
            "Epoch 26/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5432 - acc: 0.8083\n",
            "Epoch 27/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5328 - acc: 0.8133\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5227 - acc: 0.8159\n",
            "Epoch 29/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5123 - acc: 0.8194\n",
            "Epoch 30/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.5118 - acc: 0.8201\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4932 - acc: 0.8243\n",
            "Epoch 32/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4918 - acc: 0.8267\n",
            "Epoch 33/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4838 - acc: 0.8284\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4708 - acc: 0.8343\n",
            "Epoch 35/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4638 - acc: 0.8344\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4599 - acc: 0.8386\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4493 - acc: 0.8407\n",
            "Epoch 38/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4447 - acc: 0.8416\n",
            "Epoch 39/40\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4425 - acc: 0.8429\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.4308 - acc: 0.8450\n",
            "10000/10000 [==============================] - 5s 485us/step\n",
            "\n",
            "Test accuracy: 74.7%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}