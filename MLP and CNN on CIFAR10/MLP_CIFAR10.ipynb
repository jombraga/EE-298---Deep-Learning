{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP CIFAR10",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jombraga/EE-298---Deep-Learning/blob/master/MLP_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t8Ym2d1pNLy",
        "colab_type": "code",
        "outputId": "35959bf7-6f0e-46ea-f953-fca6b4da68a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# load mnist dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# compute the number of labels\n",
        "num_labels = len(np.unique(y_train))\n",
        "\n",
        "# convert to one-hot vector\n",
        "# e.g. 3 -> [0 0 0 1 0 0 0 0 0 0]\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# image dimensions (assumed square)\n",
        "image_size = x_train.shape[1]\n",
        "input_size = image_size * image_size * 3\n",
        "\n",
        "# resize and normalize\n",
        "x_train = np.reshape(x_train, [-1, input_size])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = np.reshape(x_test, [-1, input_size])\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# network parameters\n",
        "batch_size = 128\n",
        "hidden_units = 256\n",
        "dropout = 0.45\n",
        "\n",
        "\n",
        "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
        "model = Sequential()\n",
        "model.add(Dense(hidden_units, input_dim=input_size))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(hidden_units))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(num_labels))\n",
        "# this is the output for one-hot vector\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "# plot_model(model, to_file='mlp-mnist.png', show_shapes=True)\n",
        "\n",
        "# loss function for one-hot vector\n",
        "# use of sgd optimizer with default lr=0.01\n",
        "# accuracy is good metric for classification tasks\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# train the network\n",
        "model.fit(x_train, y_train, epochs=40, batch_size=batch_size)\n",
        "\n",
        "# validate the model on test dataset to determine generalization\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 256)               786688    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 855,050\n",
            "Trainable params: 855,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 9s 180us/step - loss: 1.8747 - acc: 0.3282\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 9s 174us/step - loss: 1.6758 - acc: 0.4009\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 9s 171us/step - loss: 1.5975 - acc: 0.4301\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 8s 170us/step - loss: 1.5342 - acc: 0.4542\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 1.4908 - acc: 0.4694\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 8s 166us/step - loss: 1.4674 - acc: 0.4769\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.4282 - acc: 0.4927\n",
            "Epoch 8/40\n",
            "50000/50000 [==============================] - 8s 170us/step - loss: 1.4079 - acc: 0.4978\n",
            "Epoch 9/40\n",
            "50000/50000 [==============================] - 9s 172us/step - loss: 1.3851 - acc: 0.5051\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 8s 166us/step - loss: 1.3603 - acc: 0.5159\n",
            "Epoch 11/40\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 1.3459 - acc: 0.5196\n",
            "Epoch 12/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.3222 - acc: 0.5274\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.3039 - acc: 0.5366\n",
            "Epoch 14/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.2834 - acc: 0.5428\n",
            "Epoch 15/40\n",
            "50000/50000 [==============================] - 8s 166us/step - loss: 1.2721 - acc: 0.5495\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 1.2536 - acc: 0.5524\n",
            "Epoch 17/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.2377 - acc: 0.5603\n",
            "Epoch 18/40\n",
            "50000/50000 [==============================] - 8s 167us/step - loss: 1.2272 - acc: 0.5605\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.2098 - acc: 0.5683\n",
            "Epoch 20/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.1974 - acc: 0.5715\n",
            "Epoch 21/40\n",
            "50000/50000 [==============================] - 8s 163us/step - loss: 1.1783 - acc: 0.5787\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.1712 - acc: 0.5827\n",
            "Epoch 23/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.1650 - acc: 0.5838\n",
            "Epoch 24/40\n",
            "50000/50000 [==============================] - 9s 170us/step - loss: 1.1480 - acc: 0.5908\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 8s 167us/step - loss: 1.1375 - acc: 0.5938\n",
            "Epoch 26/40\n",
            "50000/50000 [==============================] - 8s 162us/step - loss: 1.1345 - acc: 0.5969\n",
            "Epoch 27/40\n",
            "50000/50000 [==============================] - 8s 167us/step - loss: 1.1217 - acc: 0.5985\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 9s 173us/step - loss: 1.1048 - acc: 0.6056\n",
            "Epoch 29/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.1020 - acc: 0.6085\n",
            "Epoch 30/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.0974 - acc: 0.6070\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 1.0837 - acc: 0.6117\n",
            "Epoch 32/40\n",
            "50000/50000 [==============================] - 8s 167us/step - loss: 1.0740 - acc: 0.6175\n",
            "Epoch 33/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.0705 - acc: 0.6186\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 8s 170us/step - loss: 1.0617 - acc: 0.6193\n",
            "Epoch 35/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.0555 - acc: 0.6226\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 8s 164us/step - loss: 1.0388 - acc: 0.6318\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 8s 165us/step - loss: 1.0384 - acc: 0.6302\n",
            "Epoch 38/40\n",
            "50000/50000 [==============================] - 9s 174us/step - loss: 1.0296 - acc: 0.6314\n",
            "Epoch 39/40\n",
            "50000/50000 [==============================] - 8s 169us/step - loss: 1.0294 - acc: 0.6316\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.0156 - acc: 0.6379\n",
            "10000/10000 [==============================] - 1s 89us/step\n",
            "\n",
            "Test accuracy: 51.9%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
